description = "Sparkpipe text processing and analytic operations developed for the XDATA project"
group = "software.uncharted.sparkpipe"
version = "0.1.0"

// project level shared version variables
ext {
  dependencyScalaVersion = "2.11"
  scalaVersion = "2.11.8"
  sparkVersion = "2.0.1"
  cdhVersion="1.2.3"
}

// extra jars for plugins
buildscript {
  repositories {
    mavenCentral()
    jcenter()
    maven {
      url = "https://repository.cloudera.com/artifactory/cloudera-repos"
    }
  }

  dependencies {
    classpath "com.github.maiflai:gradle-scalatest:0.10"
    classpath 'org.scoverage:gradle-scoverage:1.0.9'
    classpath "org.github.ngbinh.scalastyle:gradle-scalastyle-plugin_2.11:0.8.2"
  }
}

apply plugin: 'scala'
apply plugin: 'maven'
apply plugin: 'maven-publish'
apply plugin: 'idea'
apply plugin: 'scalaStyle'
//apply plugin: 'scoverage'
apply plugin: 'com.github.maiflai.scalatest'

// run scala style and code coverage checks as part of the check phase
check.dependsOn "scalaStyle"
//check.dependsOn "checkScoverage"

// task to update the gradle wrapper
task wrapper(type: Wrapper) {
  gradleVersion = '2.13'
}

// extra configurations
configurations {
  provided
  compile.extendsFrom provided
}

// generate lib jar
jar {
    version =  version
    dependsOn configurations.runtime
    from {
        (configurations.runtime - configurations.provided).collect {
            it.isDirectory() ? it : zipTree(it)
        }
    } {
        exclude "META-INF/*.SF"
        exclude "META-INF/*.DSA"
        exclude "META-INF/*.RSA"
    }
}

// generate javadocs
task docs(type: ScalaDoc) {
    source = sourceSets.main.allScala
}

// creates a jar containing the scaladoc output
task docsJar(type: Jar, dependsOn: docs) {
    classifier = 'javadoc'
    from docs.destinationDir
}
docsJar.dependsOn docs

// creates a jar containing the source code
task sourcesJar(type: Jar) {
    classifier = 'sources'
    from sourceSets.main.allSource
}

// creates a jar containing the test source code
task testJar(type: Jar) {
    classifier = 'tests'
    from sourceSets.test.output
}

artifacts {
    archives docsJar, testJar, sourcesJar
}

// configure the idea plugin
idea {
  module {
    inheritOutputDirs = false
    outputDir = file("$buildDir/classes/main/")
    scopes.PROVIDED.plus += [ configurations.provided ]
  }
}

// configure scala style checking plugin
scalaStyle {
  configLocation = "scalastyle_config.xml"
  includeTestSourceDirectory = true
  source = sourceSets.main.allScala
  testSource = sourceSets.test.allScala
  failOnWarning = true
  verbose = true
}

// configure scoverage plugin
//checkScoverage {
//  minimumRate = 0.75
//}

// Test and scoverage tests should be forced to single threaded execution
// since Spark can't run multiple contexts within in a single JVM.
test {
  maxParallelForks = 1
}

//testScoverage {
//  maxParallelForks = 1
//}

// target 1.7 JVM
sourceCompatibility = 1.7
targetCompatibility = 1.7

// repositories for dependencies - use environment variables to configure an internal
// maven repository such as an Artifactory instance to install artifacts to.
repositories {
  mavenCentral()
  mavenLocal()
  maven {
    url = "https://repository.cloudera.com/artifactory/cloudera-repos"
  }
  if (System.env.MAVEN_REPO_URL) {
    maven {
      url = "${System.env.MAVEN_REPO_URL}/snapshots"
    }
    maven {
      url = "${System.env.MAVEN_REPO_URL}/internal"
    }
  }
}

// publishing setup - url, username, password need to be stored in environment
// variables
publishing {
  publications {
    maven(MavenPublication) {
      from components.java
      artifact docsJar
      artifact sourcesJar
      artifact testJar
    }
  }
}
publishing {
  repositories {
    maven {
      if (version.endsWith("SNAPSHOT")) {
        url "${System.env.MAVEN_REPO_URL}/snapshots"
      } else {
        url "${System.env.MAVEN_REPO_URL}/internal"
      }
      credentials {
        username "${System.env.MAVEN_REPO_USERNAME}"
        password "${System.env.MAVEN_REPO_PASSWORD}"
      }
    }
  }
}

publish << {
    if (System.env.MAVEN_REPO_URL == null) {
        throw new GradleException("Can't publish - missing MAVEN_REPO_URL environment variable")
    }
    if (System.env.MAVEN_REPO_USERNAME == null) {
        throw new GradleException("Can't publish - missing MAVEN_REPO_USERNAME environment variable")
    }
    if (System.env.MAVEN_REPO_PASSWORD == null) {
        throw new GradleException("Can't publish - missing MAVEN_REPO_PASSWORD environment variable")
    }
}

// Jars this project depends on
dependencies {
  // Compile config - needed to build and required at runtime
  compile "software.uncharted.sparkpipe:sparkpipe-core:1.1.0"
  compile "org.clapper:grizzled-slf4j_$dependencyScalaVersion:1.0.2"
  compile "joda-time:joda-time:2.9.4"
  compile "org.joda:joda-convert:1.8.1"

  // Provided config - needed to compile, expected to be available when deployed
  provided "org.apache.spark:spark-core_$dependencyScalaVersion:$sparkVersion"
  provided "org.apache.spark:spark-mllib_$dependencyScalaVersion:$sparkVersion"
  provided "org.apache.spark:spark-sql_$dependencyScalaVersion:$sparkVersion"

  // Test related
  testCompile "org.scalatest:scalatest_$dependencyScalaVersion:3.0.1"
  testCompile "org.scalatest:scalatest_$dependencyScalaVersion:3.0.1"
  testRuntime 'org.pegdown:pegdown:1.1.0'
//  scoverage "org.scoverage:scalac-scoverage-plugin_$dependencyScalaVersion:1.1.0",
//    "org.scoverage:scalac-scoverage-runtime_$dependencyScalaVersion:1.1.0"
}
